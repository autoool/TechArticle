大数据技术起源于Google 2004年前后发布的三篇论文：
1）分布式文件系统GFS
2）大数据分布式计算框架MapReduce
3）NoSQL 数据库系统BigTable

搜索引擎：网页抓取，索引构建
Lucene 开源项目的创始人 Doug Cutting 开发开源搜索引擎Nutch。
Facebook 发布Hive
Yarn将MapReduce的执行引擎和资源调度分开，资源调度系统。
2012年Spark
MapReduce、 Spark 计算框架处理的业务场景被称为批处理计算，或者大数据离线计算。
大数据流计算（大数据实时计算）：Storm / Flink / Spark Streaming
NoSQL系统处理的主要是大规模的海量数据的存储和访问。
主要应用场景：数据分析、数据挖掘、机器学习

### Lesson3  应用场景
数据仓库时代-》数据挖掘时代-》机器学习时代
金融领域：大数据风控

### Lesson4  移动计算比移动数据更划算

思考题：互联网系统架构有一条重要的原则：尽量使用无状态的服务。

不同服务实例之间不共享状态，也就是不持有数据，用户请求给任何一个服务实例计算，处理结果都是一样的。

### Lesson5  从RAID看垂直伸缩到水平伸缩的演化

首先要解决的问题就是，大数据存储问题。

单机时代：主要解决方案RAID（独立磁盘冗余阵列）

主要是为了改善磁盘的存储容量、读写速度，增强磁盘的可用性和容错能力。实现数据在多块磁盘上的并发读写和数据备份。

分布式时代：分布式文件系统

大数据存储需要解决的几个问题：

1）存储容量

2）读写速度

3）数据可靠性

- RAID几种解决方案
磁盘消耗时间最多在于寻址操作。![RAID](..\..\images\bigdata\RAID.jpg)

  1）RAID0

  并发写入（读取）N块磁盘，读写速度快。

  缺点：不做数据备份，只要有一块损坏，数据完整性就被破坏。

  2) RAID1

  一份数据同时写入两块磁盘，通过复制数据的方式自动修复，具有极高的可靠性。

  3) RAID10

  RAID0 和RAID1 结合。

  利用率低，一半的磁盘都用来备份数据。

  RAID3  N-1块磁盘写入数据，第N跨磁盘写入校验文件。任何一块磁盘损坏，都可以依赖其它磁盘进行修复。

  4) RAID5

  使用更多的方案，校验数据螺旋式写入所有磁盘中。校验数据的修改平均到每一块磁盘。避免RAID3频繁写坏一块磁盘。

  5) RAID6

数据写入N-2块磁盘，其余两块写入校验数据。

### Lesson6  HDFS依然是存储的王者

- HDFS如何实现大数据高速、可靠的存储和访问？

RAID的设计理念扩大到整个分布式服务器集群。

- HDFS是在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。

- HDFS如何保证存储的高可用性呢？

NameNode采用主从热备的方式提供高可用服务，如下图：

![namenode高可用性](..\..\images\bigdata\namenode高可用性.png)



性能和体验可以差一些，但是一定要保证可用性。

保证系统可用性策略：冗余备份、失效转移、降级限流。

### Lesson7 为什么说MapReduce既是编程模型又是计算框架？

解决大规模数据分布式计算方案-MapReduce

开发人员必须基于MapReduce编程模型进行编程开发，然后将程序通过MapReduce计算框架分发到Hadoop集群中运行。

### Lesson8 MapReduce计算框架如何运行
![mapreduce执行过程](..\..\images\bigdata\mapreduce执行过程.png)

- 数据合并与连接操作：Shuffle
相同的 Key 一定会被发送给相同的 Reduce 进程。
整个mapReduce过程中最难、最消耗性能的地方。

###Lesson9 Yarn资源调度框架
Yarn: Yet Anothrt Resource Negotiator
包括两部分：Resource Manager和Node Manager

### Lesson10 能从Hadoop学到什么
一主多从架构方案。
大数据领域的一个架构模式：集中管理，分布存储于计算。

### lesson11 Hive如何让MapReduce实现SQL操作

RDD 是Spark的核心概念，是弹性数据集（Resilient Distributed Datasets）的缩写。RDD既是Spark面向开发者的编程模型，又是Spark自身架构的核心元素。
MapReduce面向过程的大数据计算；Spark面向对象的大数据计算。

### lesson12 为何Spark可以更高效？
Spark可以根据应用的复杂程度，分割成更多的计算阶段（stage）,这些计算阶段组成一个有向无环图DAG，Spark任务调度器可以根据DAG的依赖关系执行计算阶段。
- Spark更高效：
1）将前一个Reduce和后一个的Map链接起来，当作一个阶段持续计算，这种多个结算阶段依赖执行的方案可以有效减少对HDFS的访问，减少作业的调度执行次数，因此执行速度也更快。
2）Hadoop MapReduce主要使用磁盘存储shuffle过程中的数据，Spark优先使用内存进行数据存储，包括RDD数据。
- Spark作业管理：
Spark的RDD函数有两种：
1) 转换函数 调用以后得到的还是一个RDD。
2) action函数，调用以后不再返回RDD。
Spark的DAGScheduler在遇到shuffle的时候，生成一个计算阶段，遇到action函数时候，生成一个作业（job）.
关于作业、计算阶段、任务的依赖和时间先后关系可以通过下图看到：
![Spark Task Time](..\..\images\bigdata\Spark Task Time.png)

横轴方向是时间，纵轴方向是任务。两条粗线之间是一个作业，两条细线之间是一个计算阶段。一个作业至少包含一个计算阶段。水平方向红色的线是任务，每个阶段由很多个任务组成，这些任务组成一个任务集合。

- Spark的执行过程：
Spark 支持 Standalone、Yarn、Mesos、Kubernetes等多种部署方案，但原理一样。如下图：

Spark三个主要特性: **RDD的编程模型更简单，DAG切分的多阶段计算过程跟快速，使用内存存储中间计算结果更高效**














