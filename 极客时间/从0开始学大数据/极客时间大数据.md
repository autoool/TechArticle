大数据技术起源于Google 2004年前后发布的三篇论文：
1）分布式文件系统GFS
2）大数据分布式计算框架MapReduce
3）NoSQL 数据库系统BigTable

搜索引擎：网页抓取，索引构建
Lucene 开源项目的创始人 Doug Cutting 开发开源搜索引擎Nutch。
Facebook 发布Hive
Yarn将MapReduce的执行引擎和资源调度分开，资源调度系统。
2012年Spark
MapReduce、 Spark 计算框架处理的业务场景被称为批处理计算，或者大数据离线计算。
大数据流计算（大数据实时计算）：Storm / Flink / Spark Streaming
NoSQL系统处理的主要是大规模的海量数据的存储和访问。
主要应用场景：数据分析、数据挖掘、机器学习

### Lesson3  应用场景
数据仓库时代-》数据挖掘时代-》机器学习时代
金融领域：大数据风控

### Lesson4  移动计算比移动数据更划算

思考题：互联网系统架构有一条重要的原则：尽量使用无状态的服务。

不同服务实例之间不共享状态，也就是不持有数据，用户请求给任何一个服务实例计算，处理结果都是一样的。

### Lesson5  从RAID看垂直伸缩到水平伸缩的演化

首先要解决的问题就是，大数据存储问题。

单机时代：主要解决方案RAID（独立磁盘冗余阵列）

主要是为了改善磁盘的存储容量、读写速度，增强磁盘的可用性和容错能力。实现数据在多块磁盘上的并发读写和数据备份。

分布式时代：分布式文件系统

大数据存储需要解决的几个问题：

1）存储容量

2）读写速度

3）数据可靠性

- RAID几种解决方案
磁盘消耗时间最多在于寻址操作。![RAID](..\..\images\bigdata\RAID.jpg)

  1）RAID0

  并发写入（读取）N块磁盘，读写速度快。

  缺点：不做数据备份，只要有一块损坏，数据完整性就被破坏。

  2) RAID1

  一份数据同时写入两块磁盘，通过复制数据的方式自动修复，具有极高的可靠性。

  3) RAID10

  RAID0 和RAID1 结合。

  利用率低，一半的磁盘都用来备份数据。

  RAID3  N-1块磁盘写入数据，第N跨磁盘写入校验文件。任何一块磁盘损坏，都可以依赖其它磁盘进行修复。

  4) RAID5

  使用更多的方案，校验数据螺旋式写入所有磁盘中。校验数据的修改平均到每一块磁盘。避免RAID3频繁写坏一块磁盘。

  5) RAID6

数据写入N-2块磁盘，其余两块写入校验数据。

### Lesson6  HDFS依然是存储的王者

- HDFS如何实现大数据高速、可靠的存储和访问？

RAID的设计理念扩大到整个分布式服务器集群。

- HDFS是在一个大规模分布式服务器集群上，对数据分片后进行并行读写及冗余存储。

- HDFS如何保证存储的高可用性呢？

NameNode采用主从热备的方式提供高可用服务，如下图：

![namenode高可用性](..\..\images\bigdata\namenode高可用性.png)



性能和体验可以差一些，但是一定要保证可用性。

保证系统可用性策略：冗余备份、失效转移、降级限流。

### Lesson7 为什么说MapReduce既是编程模型又是计算框架？

解决大规模数据分布式计算方案-MapReduce

开发人员必须基于MapReduce编程模型进行编程开发，然后将程序通过MapReduce计算框架分发到Hadoop集群中运行。

### Lesson8 MapReduce计算框架如何运行
![mapreduce执行过程](..\..\images\bigdata\mapreduce执行过程.png)

- 数据合并与连接操作：Shuffle
相同的 Key 一定会被发送给相同的 Reduce 进程。
整个mapReduce过程中最难、最消耗性能的地方。

###Lesson9 Yarn资源调度框架
Yarn: Yet Anothrt Resource Negotiator
包括两部分：Resource Manager和Node Manager

### Lesson10 能从Hadoop学到什么
一主多从架构方案。
大数据领域的一个架构模式：集中管理，分布存储于计算。

### lesson11 Hive如何让MapReduce实现SQL操作

RDD 是Spark的核心概念，是弹性数据集（Resilient Distributed Datasets）的缩写。RDD既是Spark面向开发者的编程模型，又是Spark自身架构的核心元素。
MapReduce面向过程的大数据计算；Spark面向对象的大数据计算。

### lesson12 为何Spark可以更高效？
Spark可以根据应用的复杂程度，分割成更多的计算阶段（stage）,这些计算阶段组成一个有向无环图DAG，Spark任务调度器可以根据DAG的依赖关系执行计算阶段。
- Spark更高效：
1）将前一个Reduce和后一个的Map链接起来，当作一个阶段持续计算，这种多个结算阶段依赖执行的方案可以有效减少对HDFS的访问，减少作业的调度执行次数，因此执行速度也更快。
2）Hadoop MapReduce主要使用磁盘存储shuffle过程中的数据，Spark优先使用内存进行数据存储，包括RDD数据。
- Spark作业管理：
Spark的RDD函数有两种：
1) 转换函数 调用以后得到的还是一个RDD。
2) action函数，调用以后不再返回RDD。
Spark的DAGScheduler在遇到shuffle的时候，生成一个计算阶段，遇到action函数时候，生成一个作业（job）.
关于作业、计算阶段、任务的依赖和时间先后关系可以通过下图看到：
![Spark Task Time](..\..\images\bigdata\Spark Task Time.png)

横轴方向是时间，纵轴方向是任务。两条粗线之间是一个作业，两条细线之间是一个计算阶段。一个作业至少包含一个计算阶段。水平方向红色的线是任务，每个阶段由很多个任务组成，这些任务组成一个任务集合。

- Spark的执行过程：
Spark 支持 Standalone、Yarn、Mesos、Kubernetes等多种部署方案，但原理一样。如下图：

Spark三个主要特性: **RDD的编程模型更简单，DAG切分的多阶段计算过程跟快速，使用内存存储中间计算结果更高效**

### Lesson14 BigTable的开源实现： HBase
NoSQL 主要指非关系的、分布式的、支持海量数据存储的数据库设计模式。
- HBase 可伸缩架构
HBase的伸缩性主要依赖其可分裂的HRegion及可伸缩的分布式文件系统HDFS实现。
![HBase](..\..\images\bigdata\HBase.png)
- HBase 可扩展数据模型
如何做到可扩展的数据结构设计？
1）许多NoSQL数据库使用列族（ColumnFamily）设计，是其中一个解决方案，一种面向列族的系数矩阵存储格式。在创建表的时候，只需要指定列族的名字，无需指定字段（Column）.在数据写入时再指定。
- HBase的高性能存储
HBase使用LSM树的数据结构进行数据存储。
LSM树全名 Log Structed Merge Tree (Log结构合并树)。数据写入时候以Log方式连续写入，然后异步对磁盘上的多个LSM树进行合并。
LSM树可以看作是一个N阶合并树，同时在内存中是一个排序树。
需要进行读操作时，总是从内存中的排序树开始搜索，如果没有找到，就从磁盘上的排序树顺序查找。
在LSm树上进行一次数据更新不需要磁盘访问，在内存即可完成。当数据访问以写为主，而读操作则集中在最近写入的数据上时，使用LSM树可以极大程度地减少磁盘的访问次数，加快访问速度。

### Lesson15 流式计算的代表：Storm 、Flink 、Spark Streaming
- Storm
  最早使用消息队列。
  ![Storm 流处理流程](..\..\images\bigdata\Storm 流处理流程.png)
  无需关注数据的流转、消息的处理和消费，只要编程开发数据处理的逻辑bolt和数据源的逻辑spout，以及它们之间的拓扑逻辑关系toplogy,提交到storm上运行即可。

  - Storm架构

    ![Storm架构](..\..\images\bigdata\Storm架构.png)

nimbus是集群的Master,负责集群的管理、任务分配等。supervisor是Salve,是真正完成计算的地方，每个supervisor启动多个worker进程，每个worker上运行多个task,而task就是spout或者bolt。supervisor和nimbus通过Zookeeper完成任务分配、心跳检测等操作。

- Spark Streaming

  利用Spark的分片和快速计算的特性，将实时传出进来的数据按照时间进行分段，把一段时间传出进来的数据合并在一起，当做一批数据，交给Spark处理。

  Spark Streaming 数据分段、分批过程图示：

  ![Spark Streaming 数据分段、分批过程](..\..\images\bigdata\Spark Streaming 数据分段、分批过程.png)


- Flink

  不管是流处理还是批处理，Flink运行时的执行引擎是相同的，只是数据源不同。

  Flink处理实时数据流的方式跟Spark Streaming也很相似，将流数据分段后，一小批一小批的处理。流处理算是Flink里的“一等公民”，Flink对流处理的支持也更加完善，它可以对数据流执行window操作，将数据流切分到一个一个的window里，进而进行计算。

  window: 将数据切分到一段时间窗口。

  Flink流数据处理流程图示：

  ![Flink 流数据处理流程](..\..\images\bigdata\Flink 流数据处理流程.png)

### Lesson16  ZooKeeper 如何保证数据一致性

因为服务器集群环境的软硬件故障随时会发生，多台服务器对一个数据记录保持一致，需要的技巧和设计。

分布式系统的一致性与ZooKeeper的架构

如果不同应用程序（Client）或者DataNode做出的关于主服务器是否可用的判断不同，就会导致HDFS集群混乱。称作“脑裂”。

- 如何避免脑裂？
  多台服务器状态一致性解决方案ZooKeeper。

- Paxos算法与Zookeeper架构

  - Paxos算法，多台服务器通过内部的投票表决机制决定一个数据的更新与写入。

  Paxos算法比较复杂，为了简化实现，ZooKeeper使用ZAB（ZooKeeper Atomic Broadcast ，ZooKeeper原子消息广播协议）算法协议。ZooKeeper系统中所有服务器都存储相同的数据，数据没有分片存储，不满足分区耐受性。因此，ZooKeeper集群的性能会随着服务器数量的增加而下降。

  ZooKeeper通过Paxos选举算法实现数据强一致性，并为各种大数据系统提供主服务器选举服务。

  CAP原则：指在一个分布式系统中，Consistency(一致性)、Availability(可用性)、Partitiontolerance(分区容错性)，三者不可兼得。

  ### Lesson17  技术应用场景

  - 技术和产品

  通常会用Hive或者Spark SQL这样的大数据仓库工具进行大数据分析和计算。

  比较特殊的是HBase，作为NoSQL存储系统，一般和Hadoop大数据集群分离部署。

  HBase 应用场景：满足在线业务数据存储访问需求，通常是OLTP(在线事务处理)系统的一部分。

  几本技术书籍《Effective Java》 《敏捷软件开发》《企业应用架构模式》



  ### Lesson18 如何开发一个大数据SQL引擎

  银行的统计报表SQL，打印出来两张A4纸，好可怕啊。

  标准SQL和Hive QL的差别：

  1）语法表达方式

  2）Hive SQL支持的语法元素比标准SQL要少很多。比如，数据仓库领域主要的测试集TPC-H所有的SQL语句Hive都不支持，尤其是Hive不支持复杂的嵌套子查询。

  **难点在于如何将复杂的嵌套子查询消除掉**，也就是where条件里不包含select。

  SQL的理论基础的关系代数，关系代数主要操作只有5种：并、差、积、选择、投影。

  嵌套子查询可以等价转换成一个join操作。

  比如：not in 可以使用left out join 和 lef semi join等价转换

  **TPC-H 的测试 SQL**

  - 阻止SQL注入攻击的原理：

  从数据库引擎的工作机制解释PrepareStatement和MyBatis的防注入攻击原理。



  ### Lesson 19 Spark的性能优化案例分析（上）

  了解Spark的运行机制。

  Apache 开源社区的组织和参与方式

  软件性能优化：

  1. 没有经过性能测试的软件
  2. 不了解其架构设计的软件

  软件的主要性能指标：

  - 响应时间：完成一次任务（请求）花费的时间
  - 并发数：同时处理的任务数（请求数）
  - 吞吐量：单位时间内完成的任务数（请求数、事务数、查询数……）
  - 性能计数器：System Load、线程数、进程数、CPU、内存、磁盘、网络使用率等

  性能优化的一般过程：

  1. 做性能测试，分析性能状况和瓶颈点
  2. 针对软件架构设计进行分析，寻找导致性能问题的原因
  3. 修改相关代码和架构，进行性能优化
  4. 做性能测试，对比是否提升性能，并寻找下一个性能瓶颈

  - 大数据软件性能优化

  1. **SQl语句优化**
  2. **数据倾斜处理。** 数据倾斜是指当两张表进行join时候，其中一张表join的某个字段值对应的数据行数特别多，那么在shuffle的时候，该字段(key)对应的所有记录都会被partition到同一个Reduce任务，导致这个任务长时间无法完成。
  3. **MapReduce、Spark代码优化。** 要处理数据的特点、计算的目标、设计合理的代码处理逻辑。
  4. **配置参数优化。** 比如Yarn的每个Container包含的CPU个数和内存数目，HDFS数据块的大小和复制数等。
  5. **大数据开源软件代码优化 。**

  - Spark性能优化

    借助工具分析CPU、内存、网络、磁盘四种主要计算资源的使用和Spark的计算阶段图示的对比，分析Spark的性能问题。

    各个Job与stage的时间点结合。

    思考题：性能测试，网卡是整个系统的瓶颈，程序运行过程中网卡达到最大I/O能力，整个系统都在等待网卡数据传输，性能优化建议？



  ### Lesson20 Spark的性能优化案例分析（下）

  - Spark性能优化可分解为下面几步：

  1. 性能测试，观察Spark性能特性和资源（CPU/Memory/Disk/Net）利用情况
  2. 分析、寻找资源瓶颈
  3. 分析系统架构、代码，发现资源利用关键所在，思考优化策略
  4. 代码、架构、基础设施调优，优化、平衡资源利用
  5. 性能测试，观察系统性能特性，是否达到优化目的。

  - 案例1：Spark任务文件初始化调优
  - 案例2：Spark任务调度优化

  避免一个Worker先注册先领走全部任务的情况。

  - 案例3: Spark应用配置优化

  CPU利用率比较低。

  - 案例4：**操作系统配置优化**

  **CPU处于sys状态**，说明CPU虽然很忙，但是没有执行用户计算，而是在执行操作系统的计算。

  通过跟踪Kunux内核执行命令，发现这些sys态的执行指令和Linux配置参数transparent huge pages有关，打开时 sys态CPU消耗会增加。

不同Linux版本的transparent huge pages 默认是否打开是不同的。

执行下面命令关闭：

echo never > /sys/kernel/mm/transparent_hugepage/enabled
echo never > /sys/kernel/mm/ transparent_hugepage/defrag

- 案例5 **硬件优化**

分析网卡的资源消耗，发现网络通信是性能瓶颈。网络读写通信都达到了网卡的最大吞吐能力，整个集群都在等待网络传输。

千兆网卡的最大传输速率是每秒125M。

优化手段：升级使用万兆网卡。

思考题：

从SQL写法、应用编程、参数配置，到大数据产品自身的架构原理和源码实现，有哪些可以进行性能优化的地方？

评论区内容：

SQL的写法是关键，减少重复计算，共用中间结果，分区表。

### Lesson21  从阿里内部产品看海量数据处理系统的设计（上）

Doris立项 ，NoSQL系统。设计目标支持海量KV结构的数据存储。

主要靠互联网产品盈利，基础技术产品可以选择开源技术，也可选择自己研发。

对工程师而言，业务产品的开发技术难度相对较低，如果想要更快提升自己的技术水平，去开发基础技术产品。

Doris 创新设计：

- 产品定位：海量分布式透明化KV存储引擎

- 业务价值：解决扩容迁移复杂，维护困难问题

- 产品目标：

  功能目标

  - KV存储ENgine
  - 逻辑管理 Namespace
  - 二级索引

  非功能目标：

  - 海量存储：透明集群管理，存储可替换
  - 伸缩性：线性伸缩，平滑扩容
  - 高可用：自动容错和故障转移
  - 高性能：低响应时间，高并发
  - 扩展性：灵活扩展新功能
  - 低运维成本：易管理、可监控

  约束：

  - 一致性：最终一致性

  技术指标，至少不能明显低于当前主流同类产品。

  **设计指标的设定，既不能低，如果比目前主流同类产品的指标还要差，自己再开发这样的产品没有意义；也不能太高，如果设定太高，过度承诺，让老板、用户对你未来交付的产品抱有太高期望，将来稍有不慎，无法达到期望，不仅对产品发展造成不良影响，甚至大家对你的人品都会产生怀疑。**

  **做好对别人的期望管理。**


目前网站KV数据存储解决方案：

- 国际站 UDAS-BDB

- 中文站 TT

  飞天KV Engine(Aspara)问题

  - 使用复杂
  - 性能较低

项目开发过程中遇到的问题：

1）开发困难。程序员需要知道自己存储的数据在哪台服务器

2）运维困难。增加服务器，需要开发配合，故障排查也很困难。

### Lesson22 (下) ：架构与创新

经过论证的架构技术方案，可以立即启动执行，不需要再去摸索尝试，风险可以把控。

Doris核心技术：分区路由算法、失效转移策略、集群伸缩设计方案

- 分区路由算法：

1）均衡性：数据分布均衡

2）波动性：X/(M+X)，优于一致性Hash的X/M.

难点：如何计算虚拟节点与物理节点的映射关系

每个虚拟节点对应两个对等物理节点：

Primary节点公式：

![Primary节点公式](..\..\images\bigdata\Primary节点公式.png)

Secondary节点：S=N+1+P;

- 失效转移策略

保证数据可用性的策略主要是数据存储冗余备份和数据访问失效转移。

可用性关键场景：

1）瞬时失效

2）临时失效

	服务端升级或者网络暂时不可用

	失效机器在短时间内可恢复

	恢复后数据和失效前一致

3）永久失效

	机器下线

先假设为瞬时失效，再假设为临时失效，最后永久失效。

节点失效，数据写入临时日志节点。

每份数据写两份，保证高可用。

一致性处理（版本、时间戳）

- 集群伸缩设计

分布式数据存储系统是分布式系统中最有技术挑战的领域之一。

思考题：

实际实现过程中，并没有使用上面数学模型计算虚拟节点和物理节点的映射关系。

### Lesson23 大数据基准测试带来的好处

Intell 推出测试工具HiBench

大数据基准测试：对大数据产品进行测试，检验大数据产品在不同硬件平台、不同数据量、不同计算任务下的性能表现。

推出了准实时 SQL 查询工具 Impala，适用场景：

1）简单统计查询，对单表数据进行聚合查询，查看数据分布规律

2）预查询，在进行全量数据的SQL查询之前，对抽样数据进行快速交互查询，验证数据分析师对数据的判断，方便数据分析师后续设计全量数据的查询SQL，而全量数据的SQL还是要运行在Hive。

负载（workload)

HiBench：

- Sort，对数据进行排序大数据程序
- WordCount、词频统计大数据计算程序
- ……

学习大数据，验证自己大数据平台性能的工具。

大部分学习大数据都停留在安装了Hadoop以后。

- 小结

同类技术问题的解决方案不会只有一个，技术产品也不会只有一个，如何对比测试大数据产品，在不同应用场景中各自的优势是什么？基准测试工具，用最小成本得到测试结果。

### Lesson24 大数据性能测试工具Dew看如何快速开发大数据系统

大数据流处理系统Gearpump

### Lesson25 模块答疑：能从大厂的大数据开发实践中学到什么

软件编程分为两种：

1）编写程序直接供最终用户使用

2）编写程序供其他工程师使用

不在于公司，而在于你做的事情。

学习方法：

1）直接读原始论文 ，掌握核心设计原理 

2）官网看官方文档 ，进一步学习

3）读源码，进一步参与开发

实践分为不同的层次：

决定技术高度的依然是你是否了解大数据技术的核心原理，真正对一个技术的掌握是需要掌握其细节。

1）第一个层次练习实战

2）第二个层次应用实践：在应用中解决问题

3）第三个层次是开发实践：大数据产品开发分两种。一种是重新开发，从头设计开发一个大数据系统；另一种是参与开源大数据产品的开发。

别人根本不会在乎你的感受和你的问题，不会把你想要的东西装在精美的礼盒里打上蝴蝶结送到你面前。你也不必在乎这个世界怎么看你，只要你想要，你就可以拼尽全力为自己争取，为自己创造机会。























